\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{subfig}
%%%%%%%%%%%%%%%%%%%%%%%%Python File Embedding
\usepackage{listings}
\usepackage{xcolor}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
%\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}
\lstdefinestyle{mystyle}{
    %backgroundcolor=\color{white},   
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4
}
\lstset{style=mystyle}

\title{Deep Learning Action Recognition \\ "Drinking--Cooking"}
\author{Mehdi Gorjian }
\date{}

\begin{document}
\maketitle

\section{Topic}
This is a Deep Learning Action Recognition project which was trained on a GPU server to recognize "Drinking Activity".
\section{Dataset}
I have implemented different sources to prepare the dataset such as Kinetics, ActivityNet and Youtube. The files were videos with the approximate length of 10 sec.\\
I wrote a code to extract the frames from the videos, put them in a specific folder and rename them. I extracated 3907 images for drinking and 7831 images for cooking as the training dataset with Data Augmentation.
\section{DNN Model}
\subsection{Architecture}
I got the benefit of utilizing Transfer Learning - Fine Tuning from ResNet50 trained on the "ImageNet". Then applied a CNN to it in order to be trained on my custom dataset. For prediction part, I took advantage of the temporal nature of videos, specifically the assumption that subsequent frames in a video will have similar semantic contents. (I used 128 frames in the sequence.)\\


\begin{lstlisting}[language=python]
baseModel = ResNet50(include_top=False, weights="imagenet", input_tensor=Input(shape=(224, 224, 3)), input_shape=(244,244,3)) 
headModel = baseModel.output
headModel = AveragePooling2D(pool_size=(7, 7))(headModel)
headModel = Flatten()(headModel)
headModel = Dense(512, activation="relu")(headModel)
headModel = Dropout(0.5)(headModel)
headModel = Dense(len(lb.classes_), activation="softmax")(headModel)
model = Model(inputs=baseModel.input, outputs=headModel)
for layer in baseModel.layers:
	layer.trainable = False
\end{lstlisting}
\subsection{Input Tensor Shape}
\textbf{Drinking Tensor Shape:}\\
$X\_Train = (5320, 224,224,3)$\\
$X\_Test = (1773, 224,224,3)$\\
\textbf{Cooking Tensor Shape:}\\
$X\_Train = (5873, 224,224,3)$\\
$X\_Test = (1958, 224,224,3)$

\subsection{Layer Structure}

\textbf{Drinking Layer Structure:}
\begin{itemize}
    \item AveragePooling2D Layer: Pool(7,7)
    \item Flatten Layer
    \item Dense Layer: $512$ + Regularization l1
    \item Dropout Layer: $50\%$
    \item Softmax Prediction
\end{itemize}
\textbf{Cooking Layer Structure:}
\begin{itemize}
    \item AveragePooling2D Layer: Pool(7,7)
    \item Flatten Layer
    \item Dense Layer: $512$ + Regularization l1
    \item Dropout Layer: $50\%$
    \item Softmax Prediction
\end{itemize}

\section{Hyper--parameters}
\subsection{List and Range of Hyper--parameters}
\begin{center}
\begin{tabular}{|c|c|}
\hline
  Batch Size   &  32, 64 \& 128\\
  Epoch        &  10 - 50\\
  Dropout      &  0.1 - 0.5\\
\hline
\end{tabular}
\end{center}

\subsection{Optimal Hyper--parameters}
\begin{center}
\begin{tabular}{|c|c|}
\hline
  Batch Size   &  32\\
  Epoch        &  35\\
  Dropout      &  0.5\\
\hline
\end{tabular}
\end{center}

\subsection{Improvement and Performance}
\begin{itemize}
    \item Keras callbacks can help to fix bugs more quickly, and to build better models. They can help to visualize how the modelâ€™s training is going, and can even help prevent overfitting by implementing checkpoints or customizing the learning rate on each iteration. A callback is a set of functions to be applied at given stages of the training procedure.
    \item I used a ModelCheckPoint callback to save the model after each epoch and to check the performance of the model. Before utilizing the checkpoint, I set the epochs to 50, however the checkpoint technique, illustrated that there is no improvement after epoch 10.
    \item I implemented EarlyStopping callback to adjust the optimized Epochs numbers.
    \item Adding (l1) Regularizaion to the FC layer. It had a good effects on improvement to the project.
    \item Adding ModelCheckpoint
    \item Adding RemoteMonitor
    \item Adding ReduceLROnPlateau
    \item Meanwhile, I got the benefits of TensorBoard visualization tool to track the training process in live.
    \item Reducing prediction flickerring
    \item Changing prediction to show "computing..." text when prediction is out of the boundary
    \item Revising the dataset: adding and removing some photos and balance them
    \item Bug fixing

\end{itemize}


\section{Annotated Code}
\subsection{Training Part (revised)}
\lstinputlisting [language=python]{train_v6.py}


\section{Running Instruction}
\subsection{Install Dependencies}
\begin{itemize}
    \item keras
    \item numpy
    \item opencv
\end{itemize}


\section{Prediction Running}

\begin{lstlisting}[language=python]

python predict_video.py --model model/activity.model --label-bin model/lb.pickle 
--input "YOUR VIDEO PATH" --output output/"ARBITRARY NAME".avi 
--action drinking --size 128

\end{lstlisting}

\subsection{Video Link}
Playlist link \textcolor{blue}{\href{https://www.youtube.com/watch?v=LGWF0j00oMI&list=PLHQn6Zmgbs7lScSfC6COPhtF7Hu57teDO}{$>>HERE<<$}}\\\\
or
\begin{verbatim}
https://www.youtube.com/watch?v=LGWF0j00oMI&list=PLHQn6Zmgbs7lScSfC6COPhtF7Hu57teDO
\end{verbatim}

\section{Performance, Loss and Accuracy Figures}


% \begin{figure}[h]
% \begin{tabular}{ccc}
%       \subfloat[Performance after 50 epochs]{\includegraphics[width=.6\textwidth]{fig1.png}}&  
%       \subfloat[Performance after 10 epochs]{\includegraphics[width=.6\textwidth]{eval.png}}&
%       \subfloat[Training procedure between epoch 8--12]{\includegraphics[width=.6\textwidth]{8-12.png}}\\
      
%      \subfloat[Training procedure between epoch 45--50]{\includegraphics[width=.6\textwidth]{45-50.png}}& 







 
   
   


% \begin{figure}[h]
%     \centering
%     \includegraphics[width=.65\textwidth]{fig2.png}
%     \caption{Loss | Acc after 50 Epochs}
% \end{figure}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=.65\textwidth]{fig_v1.png}
%     \caption{Loss--Acc after 10 Epochs}
% \end{figure}
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=.6\textwidth]{epoch-acc.png}
%     \caption{Loss--Acc logs performance}
% \end{figure}
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=.6\textwidth]{epoch-loss.png}
%     \caption{Epoch--Loss logs performance}
% \end{figure}
% \newpage
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%% V6
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=.6\textwidth]{rep6.png}
%     \caption{Performance--Project VI}
% \end{figure}
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=.6\textwidth]{fig_v6.png}
%     \caption{Loss--Acc--Project VI}
% \end{figure}
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=.6\textwidth]{ep_30_34_6.png}
%         \caption{Training procedure between epoch 30--34--Project VI}
% \end{figure}
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=.6\textwidth]{ep_4-_44_6.png}
%         \caption{Training procedure between epoch 40--44--Project VI}
% \end{figure}
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=.6\textwidth]{ep_acc_6.png}
%     \caption{Loss--Acc logs performance--Project VI}
% \end{figure}
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=.6\textwidth]{ep_loss_6.png}
%     \caption{Epoch--Loss logs performance--Project VI}
    
% \end{tabular}
% \end{figure}
\end{document}
